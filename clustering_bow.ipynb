{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clustering_bow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-Ehf9qV1Om-B",
        "WkviBLH8OseZ",
        "3PtvkGwuOu3-",
        "oXuR13Y6O7LP",
        "ZaeJM9QdO9uM",
        "Yu0UcyGI7GHb",
        "GwKW-v7HyqHO",
        "YSssAgSoxrOo",
        "4u07Ttn0ljUA",
        "5vjt8H2Glrwi",
        "NfRO3gt9lxNs",
        "LZhd2HGVQU-6",
        "ijZGf84GPuQC",
        "ZrmcgBQTRBVg",
        "V9svTIM7l1Mm",
        "syO4v7Gj4qz6",
        "7dxQi4R3UUDK",
        "WEEgCWq_UZ6X",
        "FwaCdvXZUfRH",
        "7ofKEXJKUpTE",
        "jKHXLUwnUw55"
      ],
      "authorship_tag": "ABX9TyP/i4kHGHRUMzLnrhy+uvEP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csralvall/online_game_toxicity/blob/main/clustering_bow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ehf9qV1Om-B"
      },
      "source": [
        "### Import utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFh8HD-mWVnw"
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkviBLH8OseZ"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBtxeZnzVXjW"
      },
      "source": [
        "!pip install -U kaggle pip setuptools wheel pandas sklearn numpy wget mr4mp\n",
        "clear_output()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PtvkGwuOu3-"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maXhDvByUuFn"
      },
      "source": [
        "from google.colab import drive, files\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pickle\n",
        "import mr4mp\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.cluster import KMeans\n",
        "from timeit import default_timer\n",
        "from collections import Counter"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UvkuLsSU6-z"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXuR13Y6O7LP"
      },
      "source": [
        "### Mount storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3mjkCTQWaLo",
        "outputId": "93da7e27-188a-4633-f773-e9a39ec3f386"
      },
      "source": [
        "# mount google drive unit to save computationally expensive results\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaeJM9QdO9uM"
      },
      "source": [
        "### Get subset of whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVhIh1OfWkF_"
      },
      "source": [
        "# english chats from original dataset with anotations\n",
        "eng_annotated = '/content/drive/MyDrive/nlp/dota2_chat_eng_annotated.csv'\n",
        "df_test = pd.read_csv(eng_annotated)[:10000]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu0UcyGI7GHb"
      },
      "source": [
        "### Get bad word list from memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnXy-9AwhltM"
      },
      "source": [
        "# get downloaded bad word list\n",
        "word_list = \"/content/drive/MyDrive/nlp/bad_words.txt\"\n",
        "# use set for fast queries\n",
        "bad_words = set(line.strip() for line in open(word_list, 'r'))\n",
        "# add new bad words\n",
        "bad_words.update(['noob', 'noobs', 'stfu', 'fukign', 'fuking', 'fukin', 'nooob'])\n",
        "bad_dict = dict.fromkeys(bad_words, 0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwKW-v7HyqHO"
      },
      "source": [
        "### Create Bag of Words (BOW)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wet2ZMgEGbzz"
      },
      "source": [
        "def flatten(t):\n",
        "    return [item for sublist in t for item in sublist]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zoBT44hXDXu"
      },
      "source": [
        "# function to transform chats in sets of words\n",
        "def chat_to_set(chat: [str]) -> {str}:\n",
        "    return set(chat.split())\n",
        "\n",
        "# function to join all chat sets in one big set\n",
        "def join_chat_sets(chat: {str},bag: {str}) -> {str}:\n",
        "    return bag.union(chat)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6gC4ki9XLqV"
      },
      "source": [
        "# from cleaned english chats get all of them without nan values\n",
        "chats = df_test[['tokens']].dropna().astype(str).values"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-EYQTPPGFZc"
      },
      "source": [
        "chats = flatten(chats)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kqLzNLiXdYX",
        "outputId": "d47c270c-905f-4a02-dcb6-c2aa222d99d4"
      },
      "source": [
        "# use map reduce model to create the Bag of Words (BOW)\n",
        "start = default_timer()\n",
        "pool = mr4mp.pool(10) # roughly 1hs with gpu with full eng dataset\n",
        "set_of_words = pool.mapreduce(chat_to_set, join_chat_sets, chats)\n",
        "pool.close()\n",
        "bag_of_words = dict.fromkeys(set_of_words, 0)\n",
        "print(\"Finished in \" + str(default_timer()-start) + \"s using \" + str(len(pool)) + \" process(es).\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished in 0.27319918500000995s using 10 process(es).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXE51CAMWGTp"
      },
      "source": [
        "# save bag of words in drive (very expensive to compute)\n",
        "# use when running code with full dataset\n",
        "with open('/content/drive/MyDrive/nlp/bag_of_words.pkl', 'wb') as dict_file:\n",
        "    pickle.dump(bag_of_words, dict_file)\n",
        "    dict_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSssAgSoxrOo"
      },
      "source": [
        "#### Clustering utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlacJecnxtnZ"
      },
      "source": [
        "def get_bad_vec(lexicon, chat_words):\n",
        "    for word in chat_words:\n",
        "        if word in lexicon:\n",
        "            bad_dict[word] += 1\n",
        "\n",
        "    bad_vec = np.fromiter(bad_dict.values(), dtype=int)\n",
        "    \n",
        "    return bad_vec"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHz3JL0bzAXA"
      },
      "source": [
        "def get_bow_vec(bow, chat_words):\n",
        "    for word in word_list:\n",
        "        if word in bow:\n",
        "            bow[word] += 1\n",
        "\n",
        "    bow_vec = np.fromiter(bow.values(), dtype=int)\n",
        "\n",
        "    return bow_vec"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0km18782I8rI"
      },
      "source": [
        "intensity = df_test[['intensity']].copy()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u07Ttn0ljUA"
      },
      "source": [
        "### Create bow vectors for clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaomdggXZjci"
      },
      "source": [
        "for idx, chat in enumerate(chats):\n",
        "    bow = dict.fromkeys(bag_of_words, 0)\n",
        "    lexicon = dict.fromkeys(bad_words, 0)\n",
        "    chat_intensity = intensity.loc[idx]\n",
        "    chat_words = chat.split()\n",
        "    bad_vec = get_bad_vec(lexicon, chat_words)\n",
        "    bow_vec = get_bow_vec(bow, chat_words)\n",
        "    bow_bad_int_vec = np.hstack((bow_vec, bad_vec, chat_intensity)).ravel()\n",
        "    if idx == 0:\n",
        "        bow_serie = bow_bad_int_vec\n",
        "    else:\n",
        "        bow_serie = np.concatenate((bow_serie, bow_bad_int_vec))\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vjt8H2Glrwi"
      },
      "source": [
        "### Reshape data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R-ZUWaNlaj8"
      },
      "source": [
        "bow_ncolumns = len(set_of_words) + len(bad_words) + 1\n",
        "bow_serie = bow_serie.astype('float').reshape((-1, bow_ncolumns))\n",
        "bow_matrix = bow_serie[~np.isnan(bow_serie)].reshape((-1, bow_ncolumns))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfRO3gt9lxNs"
      },
      "source": [
        "### Matrix reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVZBvVQj6EWR"
      },
      "source": [
        "def reduce_matrix(matrix: np.ndarray, *, variance_treshold: float):\n",
        "    print(f'INPUT SHAPE: {matrix.shape}')\n",
        "    # reduce all vectors to [0, 1] space\n",
        "    normalized_matrix = normalize(matrix, axis=1)\n",
        "    # compute variances in each row\n",
        "    matrix_variances = np.var(matrix, axis=0)\n",
        "    # create mask for features with high correlation (low variance)\n",
        "    bool_mask = np.where(matrix_variances < variance_treshold)\n",
        "    # filter features with high correlation (variance under treshold)\n",
        "    raked_matrix = np.delete(normalized_matrix, bool_mask, axis=1)\n",
        "    print(f'OUTPUT SHAPE: {raked_matrix.shape}')\n",
        "    return raked_matrix"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZhd2HGVQU-6"
      },
      "source": [
        "### Reduce matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLHhdTn56Ywf",
        "outputId": "fc5f0ba4-8b5d-4bfb-96a1-409625fea22f"
      },
      "source": [
        "bow_reduced = reduce_matrix(bow_matrix, variance_treshold=0.0001)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT SHAPE: (8157, 5228)\n",
            "OUTPUT SHAPE: (8157, 141)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijZGf84GPuQC"
      },
      "source": [
        "### Save matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CzQQY-Osoj7"
      },
      "source": [
        "with open('/content/drive/MyDrive/nlp/bow_serie_10000.npy', 'wb') as output_file:\n",
        "    np.save(output_file, bow_matrix)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrmcgBQTRBVg"
      },
      "source": [
        "### Load matrix from storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRqFxR3hRDxy"
      },
      "source": [
        "bow_serie = np.load('/content/drive/MyDrive/nlp/bow_serie_10000.npy')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9svTIM7l1Mm"
      },
      "source": [
        "#### Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu2EI9Ty6osz"
      },
      "source": [
        "def generate_clusters(\n",
        "    matrix: np.ndarray,\n",
        "    n_clusters: int\n",
        ") -> KMeans:\n",
        "    # generate word clusters using the KMeans algorithm.\n",
        "    print(\"\\nClustering started\")\n",
        "    # Instantiate KMeans clusterer for n_clusters\n",
        "    km_model = KMeans(n_clusters=n_clusters, random_state=3)\n",
        "    # create clusters\n",
        "    km_model.fit(matrix)\n",
        "    print(\"Clustering finished\")\n",
        "    return km_model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syO4v7Gj4qz6"
      },
      "source": [
        "### Create clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPhX4J3Z69Hx",
        "outputId": "7aca65dd-ebc2-4d42-9817-7db48f371ae6"
      },
      "source": [
        "bow_clusters = generate_clusters(bow_serie, 50)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Clustering started\n",
            "Clustering finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dxQi4R3UUDK"
      },
      "source": [
        "### Cluster utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m5VxwFj7pvE"
      },
      "source": [
        "def display_summary(clusters: KMeans):\n",
        "    cluster_count = Counter(sorted(clusters.labels_))\n",
        "    for cluster in cluster_count:\n",
        "        print (\"Cluster#\", cluster,\" - Total words:\", cluster_count[cluster])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oN0JpYkuRdp"
      },
      "source": [
        "def annotate_dataframe(clusters: KMeans, df: pd.DataFrame, col_name: str):\n",
        "    cluster_count = Counter(sorted(clusters.labels_))\n",
        "    #sort cluster centers by proximity to centroid\n",
        "    order_centroids = clusters.cluster_centers_.argsort()[:, ::-1] \n",
        "\n",
        "    clusters_df = np.zeros(len(df))\n",
        "    \n",
        "    for cluster_idx in cluster_count:\n",
        "        # get words inside each cluster\n",
        "        cluster_words = np.where(clusters.labels_ == cluster_idx)[0]\n",
        "        # anotate all chats in cluster\n",
        "        for idx in cluster_words:\n",
        "            clusters_df[idx] = int(cluster_idx)\n",
        "\n",
        "    df[col_name] = clusters_df"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEEgCWq_UZ6X"
      },
      "source": [
        "### Show info about clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p5KqB3lo15J",
        "outputId": "22e1a6cf-6658-42bf-bd73-5e400e3bbedb"
      },
      "source": [
        "display_summary(bow_clusters)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster# 0  - Total words: 234\n",
            "Cluster# 1  - Total words: 144\n",
            "Cluster# 2  - Total words: 128\n",
            "Cluster# 3  - Total words: 190\n",
            "Cluster# 4  - Total words: 156\n",
            "Cluster# 5  - Total words: 236\n",
            "Cluster# 6  - Total words: 225\n",
            "Cluster# 7  - Total words: 204\n",
            "Cluster# 8  - Total words: 108\n",
            "Cluster# 9  - Total words: 183\n",
            "Cluster# 10  - Total words: 186\n",
            "Cluster# 11  - Total words: 227\n",
            "Cluster# 12  - Total words: 211\n",
            "Cluster# 13  - Total words: 150\n",
            "Cluster# 14  - Total words: 210\n",
            "Cluster# 15  - Total words: 164\n",
            "Cluster# 16  - Total words: 90\n",
            "Cluster# 17  - Total words: 215\n",
            "Cluster# 18  - Total words: 126\n",
            "Cluster# 19  - Total words: 148\n",
            "Cluster# 20  - Total words: 134\n",
            "Cluster# 21  - Total words: 188\n",
            "Cluster# 22  - Total words: 210\n",
            "Cluster# 23  - Total words: 224\n",
            "Cluster# 24  - Total words: 137\n",
            "Cluster# 25  - Total words: 144\n",
            "Cluster# 26  - Total words: 211\n",
            "Cluster# 27  - Total words: 126\n",
            "Cluster# 28  - Total words: 206\n",
            "Cluster# 29  - Total words: 201\n",
            "Cluster# 30  - Total words: 141\n",
            "Cluster# 31  - Total words: 117\n",
            "Cluster# 32  - Total words: 111\n",
            "Cluster# 33  - Total words: 267\n",
            "Cluster# 34  - Total words: 165\n",
            "Cluster# 35  - Total words: 177\n",
            "Cluster# 36  - Total words: 190\n",
            "Cluster# 37  - Total words: 129\n",
            "Cluster# 38  - Total words: 81\n",
            "Cluster# 39  - Total words: 136\n",
            "Cluster# 40  - Total words: 140\n",
            "Cluster# 41  - Total words: 152\n",
            "Cluster# 42  - Total words: 165\n",
            "Cluster# 43  - Total words: 63\n",
            "Cluster# 44  - Total words: 205\n",
            "Cluster# 45  - Total words: 175\n",
            "Cluster# 46  - Total words: 96\n",
            "Cluster# 47  - Total words: 83\n",
            "Cluster# 48  - Total words: 161\n",
            "Cluster# 49  - Total words: 87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "628xHBsKvEXw"
      },
      "source": [
        "df_test = df_test.copy()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwaCdvXZUfRH"
      },
      "source": [
        "### Annotate cluster for each row in dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5adupRW8v7vk"
      },
      "source": [
        "annotate_dataframe(bow_clusters, df_test, 'bow_clusters')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKi61q3cjhf"
      },
      "source": [
        "df_test.to_csv(f'/content/drive/MyDrive/nlp/bow_clusters_df.csv', index=False)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gENfZmClUlbh"
      },
      "source": [
        "### Explore results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7jOXlqFw_Lu"
      },
      "source": [
        "bow_group = df_test.groupby('bow_clusters')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ofKEXJKUpTE"
      },
      "source": [
        "#### Get toxicity score for each cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Ew0GX3TClP",
        "outputId": "125b7d51-8ac7-45c2-915e-128fcc777f98"
      },
      "source": [
        "bow_group['toxicity'].sum() / bow_group.size()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bow_clusters\n",
              "0.0     0.125181\n",
              "1.0     0.083333\n",
              "2.0     0.164062\n",
              "3.0     0.047368\n",
              "4.0     0.128205\n",
              "5.0     0.063559\n",
              "6.0     0.111111\n",
              "7.0     0.122549\n",
              "8.0     0.148148\n",
              "9.0     0.098361\n",
              "10.0    0.155914\n",
              "11.0    0.158590\n",
              "12.0    0.090047\n",
              "13.0    0.073333\n",
              "14.0    0.114286\n",
              "15.0    0.054878\n",
              "16.0    0.111111\n",
              "17.0    0.125581\n",
              "18.0    0.126984\n",
              "19.0    0.108108\n",
              "20.0    0.089552\n",
              "21.0    0.106383\n",
              "22.0    0.185714\n",
              "23.0    0.098214\n",
              "24.0    0.087591\n",
              "25.0    0.097222\n",
              "26.0    0.104265\n",
              "27.0    0.055556\n",
              "28.0    0.135922\n",
              "29.0    0.099502\n",
              "30.0    0.085106\n",
              "31.0    0.111111\n",
              "32.0    0.054054\n",
              "33.0    0.071161\n",
              "34.0    0.163636\n",
              "35.0    0.067797\n",
              "36.0    0.126316\n",
              "37.0    0.069767\n",
              "38.0    0.148148\n",
              "39.0    0.088235\n",
              "40.0    0.128571\n",
              "41.0    0.078947\n",
              "42.0    0.054545\n",
              "43.0    0.190476\n",
              "44.0    0.136585\n",
              "45.0    0.131429\n",
              "46.0    0.114583\n",
              "47.0    0.060241\n",
              "48.0    0.105590\n",
              "49.0    0.091954\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKHXLUwnUw55"
      },
      "source": [
        "#### Explore clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wJe46lwxrMw",
        "outputId": "8cfed832-206f-406d-9d39-74a529d5aa7d"
      },
      "source": [
        "bow_group.get_group(11)['text']"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1535    and Io just doenst available on mid cuz like that\n",
              "1536                       ruins every single game hes in\n",
              "1537                  this qop is just ruining the moment\n",
              "1538                                      i had him muted\n",
              "1539    he just dont realize omni is the worst 5 u can...\n",
              "1540                                     what did he say?\n",
              "1541                                              nothing\n",
              "1542         gg this omni watches too much fucking slacks\n",
              "1543                                              gl next\n",
              "1544                                      my fucking tide\n",
              "1545                                              running\n",
              "1546                                               he not\n",
              "1547                                         even hitting\n",
              "1548                                                  why\n",
              "1549                                                   5k\n",
              "1550                                             all suck\n",
              "1551                                          same like u\n",
              "1552                                                  end\n",
              "1553                                  str8 end i wont def\n",
              "1554                                          can we guys\n",
              "1555                                             together\n",
              "1556                                    report our midder\n",
              "1557                                                 rofl\n",
              "1558                                                 sure\n",
              "1559                                        they blame me\n",
              "1560                                         Read he name\n",
              "1561                                          typical sea\n",
              "1562                                             can solo\n",
              "1563                                        win this game\n",
              "1564                                         just nothing\n",
              "1565                                     but he braindead\n",
              "1566                                        he braindead?\n",
              "1567                                          rip english\n",
              "1568                                          3-8 and 6-9\n",
              "1569                                               report\n",
              "1570                                                viper\n",
              "1571                                                -1400\n",
              "1572                                                   XD\n",
              "1573                                                   :(\n",
              "1574                                                    (\n",
              "1575                                                   n1\n",
              "1576                                    No desire to play\n",
              "1577                                               go end\n",
              "1578                                                 ggwp\n",
              "1579                                        stop ddos [ls\n",
              "1580                                                   =/\n",
              "1581                                      focus  ya veras\n",
              "1582                                                   ok\n",
              "1583                                            comend me\n",
              "1584                                               commed\n",
              "1585                                                   md\n",
              "1586                                                    R\n",
              "1587                                             ZADDDRRR\n",
              "1588                                                 tilt\n",
              "1589                                      2 piece of shit\n",
              "1590                                       slu4ayno ubral\n",
              "1591                na mogilu materi its slajesh pizdabol\n",
              "1592                                                  lol\n",
              "1593                                           ITS A TRAP\n",
              "1594                                                sorry\n",
              "1595                                                 rofl\n",
              "1596                                              zapomni\n",
              "1597                                         on 4 k musor\n",
              "1598                                                  LOL\n",
              "1599                                            nice hook\n",
              "1600                                                 lol \n",
              "1601                                            nc blink \n",
              "1602                                                  lol\n",
              "1603                                                  ???\n",
              "1604                                              fat boi\n",
              "1605                                            nice deny\n",
              "1606                                                  LOL\n",
              "1607                                                  wew\n",
              "1608                                               worth?\n",
              "1609                                               worth?\n",
              "1610                                         just shut up\n",
              "1611                                            noob jugg\n",
              "1612                                                 1/8?\n",
              "1613                      getting destroyed by herald axe\n",
              "1614                                               worth?\n",
              "1615                                                 wtf \n",
              "1616                                               worth?\n",
              "1617                                     fucking guardian\n",
              "1618                                 losing to herald bro\n",
              "1619                                    then what r u jug\n",
              "1620                                                  ???\n",
              "1621                                  say that when u win\n",
              "1622                                                  lol\n",
              "1623                                      just wait bitch\n",
              "1624                                                   ok\n",
              "1625                                    lets go late game\n",
              "1626                                         i shall wait\n",
              "1627                                                  wew\n",
              "1628                                  why blink in to fee\n",
              "1629                                                 Feed\n",
              "1630                                        jugg so scary\n",
              "1631                                   trash talk pa guys\n",
              "1632                                   u started it pudge\n",
              "1633                                                  end\n",
              "1634                                    you got 1877 gold\n",
              "1635                                                  lol\n",
              "1636                                                  ???\n",
              "1637                                                 jugg\n",
              "1638                                              where u\n",
              "1639                                 i save my ulti for u\n",
              "1640                                trash talk pa kunnka \n",
              "1641                                               really\n",
              "1642                                             lets see\n",
              "1643                                        trash talk pa\n",
              "1644                                            shet you \n",
              "1645                                    i dont speak poor\n",
              "1646                                                 lol \n",
              "1647                                            buyer am \n",
              "1648                                            fuck you \n",
              "1649                  dont know how to play your hero am \n",
              "1650                because your a buyer you shet hahaha \n",
              "1651                                             go away \n",
              "1652                           what happened to your mid?\n",
              "1653                                   why make am so fat\n",
              "1654                                       indog are poor\n",
              "1655                                      do u need money\n",
              "1656                                    come suck my dick\n",
              "1657                                              i pay u\n",
              "1658                                                  GAY\n",
              "1659                                             why run?\n",
              "1660                                        runner buyer \n",
              "1661                                         cuz i scared\n",
              "1662                                u run from me slardar\n",
              "1663                                                 buye\n",
              "1664                                      fuck you buyer \n",
              "1665                                                 jugg\n",
              "1666                            buyer just shit on u dude\n",
              "1667                                       buyer be like \n",
              "1668                                                buyr \n",
              "1669                                         pls quit alr\n",
              "1670                                               buyer \n",
              "1671                                                 wtf \n",
              "1672                                               buyer \n",
              "1673                                               buyer \n",
              "1674                                               buyer \n",
              "1675                            at least got money to buy\n",
              "1676                                          i rich what\n",
              "1677                                           how bout u\n",
              "1678                                           are u rich\n",
              "1679                                               buyer \n",
              "1680                                               buyer \n",
              "1681                                            wtf noob \n",
              "1682                                               buyer \n",
              "1683                                          trash talk \n",
              "1684                                                buyer\n",
              "1685                                               buyer \n",
              "1686                                                  ???\n",
              "1687                                               jhahaa\n",
              "1688                                    u calling me rich\n",
              "1689                                    thanks poor fagot\n",
              "1690                                               buyer \n",
              "1691                                                noob \n",
              "1692                                                noob?\n",
              "1693                                                daddy\n",
              "1694                                           i came alr\n",
              "1695                                                 jugg\n",
              "1696                                          creeps died\n",
              "1697                                               buyer \n",
              "1698                                       radian victory\n",
              "1699                                          its not ezz\n",
              "1700                                                  lol\n",
              "1701                                                   XD\n",
              "1702                                                   XD\n",
              "1703                                                  LOL\n",
              "1704                                                   gt\n",
              "1705                                get off my dick pudge\n",
              "1706                                     i like big dick \n",
              "1707                            u lost 2 towers 2 kill me\n",
              "1708                                               morons\n",
              "1709                                      great tp sniper\n",
              "1710                                                 GGWP\n",
              "1711                                           rough game\n",
              "1712                              bots play better u know\n",
              "1713                                     ZX @X X@@ @X X @\n",
              "1714                                           sin shluhi\n",
              "1715                                              Gg east\n",
              "1716                                               Hde on\n",
              "1717                                            On rijiy?\n",
              "1718                               insert coin, game over\n",
              "1719                     Currently In-GameDota 2Join Game\n",
              "1720                                                gg wp\n",
              "1721                              Dont attack my twrs pls\n",
              "1722                                                  end\n",
              "1723                                              because\n",
              "1724                                                 10-0\n",
              "1725                                      solo carry team\n",
              "1726                                            Best team\n",
              "1727                                               (none)\n",
              "1728                                             and play\n",
              "1729                                         emo nobo kid\n",
              "1730                                                enjoy\n",
              "1731                                                 gyro\n",
              "1732                                    they farm all day\n",
              "1733                      buy retard items  i cant blieve\n",
              "1734                                           0 teamplay\n",
              "1735                              let midas slardar fcarm\n",
              "1736                                               u feed\n",
              "1737      Enjoy ur loss u fuc,kijng garbage piece of shit\n",
              "1738                                            look alch\n",
              "1739                                              6 death\n",
              "1740                                              9 death\n",
              "1741                               in a game i carry 10-0\n",
              "1742                                           he can dmg\n",
              "1743                                                u not\n",
              "1744                                                 only\n",
              "1745                                                 Only\n",
              "1746                                         FUCKING FARM\n",
              "1747            AND WITH FARM BUY FUCKINGF RETARDED ITEMS\n",
              "1748                                         TO FARM MORE\n",
              "1749                  I CREATE MORE SPAC THAN IN UNIVERSE\n",
              "1750                                               GO END\n",
              "1751                                  u have nothing noob\n",
              "1752                                          gyro ruiner\n",
              "1753                                     SHUT THE FUCK UP\n",
              "1754                                                   ok\n",
              "1755                                                mute \n",
              "1756                                              I CARRY\n",
              "1757                                          WITH ASSIST\n",
              "1758                                               report\n",
              "1759                    FEED 6 DEATH ANYWAY TO WEAK ENEMY\n",
              "1760                                       AND BE USELESS\n",
              "1761                                      Team crusader 0\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AQTvWh0TKm2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}