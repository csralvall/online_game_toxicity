{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clustering_ftt.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wA02sevwAzaW"
      ],
      "authorship_tag": "ABX9TyN4vmek4hL3rAPYo7wKeum6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csralvall/online_game_toxicity/blob/main/clustering_ftt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsdH2QEr9WkR"
      },
      "source": [
        "### Import utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFh8HD-mWVnw"
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddPQpImtmj1m"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBtxeZnzVXjW"
      },
      "source": [
        "# install dependencies\n",
        "!pip install -U pip setuptools wheel pandas numpy gensim wget\n",
        "clear_output()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnZWWzROmmKF"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maXhDvByUuFn"
      },
      "source": [
        "# import libraries\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "from gensim.models import FastText"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTlB5ugtnHy_"
      },
      "source": [
        "### Setup dataframe print options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WJxr5-pnGYh"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF_AyP-3nMsH"
      },
      "source": [
        "### Mount storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3mjkCTQWaLo",
        "outputId": "5896d8ae-2a19-4698-e669-27c39cbf0f12"
      },
      "source": [
        "# mount google drive unit to save computationally expensive results\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSQ0ZhWFDpZX"
      },
      "source": [
        "### Load subset of whole dataset from storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVhIh1OfWkF_"
      },
      "source": [
        "# english chats from original dataset with anotations\n",
        "eng_annotated = '/content/drive/MyDrive/nlp/dota2_chat_eng_annotated.csv'\n",
        "df_test = pd.read_csv(eng_annotated)[:10000]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu0UcyGI7GHb"
      },
      "source": [
        "### Get bad word list from memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnXy-9AwhltM"
      },
      "source": [
        "# get downloaded bad word list\n",
        "word_list = \"/content/drive/MyDrive/nlp/bad_words.txt\"\n",
        "# use set for fast queries\n",
        "bad_words = set(line.strip() for line in open(word_list, 'r'))\n",
        "# add new bad words\n",
        "bad_words.update(['noob', 'noobs', 'stfu', 'fukign', 'fuking', 'fukin', 'nooob'])\n",
        "bad_dict = dict.fromkeys(bad_words, 0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA02sevwAzaW"
      },
      "source": [
        "# Some experiments with bigrams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qebh8reO6F3E",
        "outputId": "ac41dc9a-a4c4-41ff-ec94-6bbec1ac80b8"
      },
      "source": [
        "from nltk import word_tokenize \n",
        "from nltk.util import ngrams\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "bigrams = []\n",
        "trigrams = []\n",
        "for line in chats:\n",
        "    token = line.split()\n",
        "    bigrams.append(list(map(lambda x: '_'.join(x), ngrams(token, 2))))\n",
        "    trigrams.append(list(map(lambda x: '_'.join(x), ngrams(token, 3))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUOg2ySv9GcY",
        "outputId": "9db75c80-9493-4cad-b164-4ddb2d64eb4d"
      },
      "source": [
        "len(trigrams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8157"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9OIxBpF91hn"
      },
      "source": [
        "from gensim.models.phrases import Phrases, Phraser\n",
        "def build_phrases(sentences):\n",
        "    phrases = Phrases(sentences,\n",
        "                      min_count=5,\n",
        "                      threshold=7,\n",
        "                      progress_per=1000)\n",
        "    return Phraser(phrases)\n",
        "\n",
        "bigrams = build_phrases(chats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c6L5zQeAJLm"
      },
      "source": [
        "bigrams = list(map(lambda x: [x], bigrams[chats]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLFtyd44-oeL"
      },
      "source": [
        "w2v_bi = generate_embedding(bigrams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9psITMZ-uni",
        "outputId": "33e2ae40-f7e0-431e-eb17-087cf04d83c5"
      },
      "source": [
        "w2v_bi.wv.most_similar('report')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nice', 0.2529045641422272),\n",
              " ('carry', 0.20082908868789673),\n",
              " ('ggwp', 0.17018888890743256),\n",
              " ('team', 0.15016482770442963),\n",
              " ('mid', 0.13887985050678253),\n",
              " ('feed', 0.10852647572755814),\n",
              " ('guys', 0.09936434030532837),\n",
              " ('commend', 0.03476494550704956),\n",
              " ('def', 0.0330718494951725),\n",
              " ('win', 0.019886532798409462)]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbRLeXSd4gT5"
      },
      "source": [
        "# Generate word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDyWyz93qZeG"
      },
      "source": [
        "#### Fasttext embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX45YUcKsIcz"
      },
      "source": [
        "# function to create embeddings of words in each chat\n",
        "def generate_embedding_ftt(sentences: [[str]]):\n",
        "  ftt_model = FastText(\n",
        "      sentences=sentences,\n",
        "      vector_size=100,\n",
        "      window=5,\n",
        "      min_count=1,\n",
        "      workers=1\n",
        "  )\n",
        "\n",
        "  ftt_model.build_vocab(sentences, progress_per=10000)\n",
        "\n",
        "  ftt_model.train(sentences, total_examples=len(sentences), epochs=100)\n",
        "\n",
        "  return ftt_model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq2tD7FoDd_l"
      },
      "source": [
        "### Unroll chats as list of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wet2ZMgEGbzz"
      },
      "source": [
        "def flatten(t):\n",
        "    return [item for sublist in t for item in sublist]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGbEkPMkmdoM"
      },
      "source": [
        "# from cleaned english chats get all of them without nan values\n",
        "chats = df_test[['tokens']].dropna().astype(str).values\n",
        "chats = flatten(chats)\n",
        "vocab = list(map(lambda x: x.split(), chats))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XHxBPDL3BM9"
      },
      "source": [
        "#### Generate word embeddings from chat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGvt6ajrAPKr"
      },
      "source": [
        "ftt_model = generate_embedding_ftt(vocab)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-IsmMTQk4ve"
      },
      "source": [
        "# save FastText model\n",
        "ftt_model.save('/content/drive/MyDrive/nlp/fasttext.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sKtCB-e3LZF"
      },
      "source": [
        "#### Load word embeddings from disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjvUKBx23OmO"
      },
      "source": [
        "# load FastText model\n",
        "ftt_model = FastText.load('/content/drive/MyDrive/nlp/fasttext.model')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suZ6ZD-lvay6"
      },
      "source": [
        "#### Embeddings utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AisVg8TSvhUj"
      },
      "source": [
        "# generate embedding from chat\n",
        "def chat_embedding(model, chat_words):\n",
        "    chat_embedding = np.ones(100)\n",
        "    for word in chat_words:\n",
        "        if word in model.wv:\n",
        "            chat_embedding *= model.wv[word] \n",
        "    return chat_embedding"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSssAgSoxrOo"
      },
      "source": [
        "#### Clustering utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlacJecnxtnZ"
      },
      "source": [
        "def get_bad_vec(lexicon, chat_words):\n",
        "    for word in chat_words:\n",
        "        if word in lexicon:\n",
        "            bad_dict[word] += 1\n",
        "\n",
        "    bad_vec = np.fromiter(bad_dict.values(), dtype=int)\n",
        "    \n",
        "    return bad_vec"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHz3JL0bzAXA"
      },
      "source": [
        "def get_bow_vec(bow, chat_words):\n",
        "    for word in word_list:\n",
        "        if word in bow:\n",
        "            bow[word] += 1\n",
        "\n",
        "    bow_vec = np.fromiter(bow.values(), dtype=int)\n",
        "\n",
        "    return bow_vec"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0km18782I8rI"
      },
      "source": [
        "intensity = df_test[['intensity']].copy()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u07Ttn0ljUA"
      },
      "source": [
        "### Create ftt vectors for clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llLMyvqffSMz"
      },
      "source": [
        "ftt_serie = np.array([])\n",
        "for idx, chat in enumerate(chats):\n",
        "    lexicon = dict.fromkeys(bad_words, 0)\n",
        "    chat_intensity = intensity.loc[idx]\n",
        "    chat_words = chat.split()\n",
        "    bad_vec = get_bad_vec(lexicon, chat_words)\n",
        "    ftt_embedding = chat_embedding(ftt_model, chat_words)\n",
        "    ftt_bad_int_vec = np.hstack((ftt_embedding, bad_vec, chat_intensity)).ravel()\n",
        "    ftt_serie = np.concatenate((ftt_serie, ftt_bad_int_vec))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vjt8H2Glrwi"
      },
      "source": [
        "#### Reshape data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR_-iU2Iwknv"
      },
      "source": [
        "ftt_ncolumns = ftt_model.wv.vectors.shape[1] + len(bad_words) + 1\n",
        "ftt_serie = ftt_serie.astype('float').reshape((-1, ftt_ncolumns))\n",
        "ftt_matrix = ftt_serie[~np.isnan(ftt_serie)].reshape((-1, ftt_ncolumns))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfRO3gt9lxNs"
      },
      "source": [
        "#### Matrix reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVZBvVQj6EWR"
      },
      "source": [
        "def reduce_matrix(matrix: np.ndarray, *, variance_treshold: float):\n",
        "    print(f'INPUT SHAPE: {matrix.shape}')\n",
        "    # reduce all vectors to [0, 1] space\n",
        "    normalized_matrix = normalize(matrix, axis=1)\n",
        "    # compute variances in each row\n",
        "    matrix_variances = np.var(matrix, axis=0)\n",
        "    # create mask for features with high correlation (low variance)\n",
        "    bool_mask = np.where(matrix_variances < variance_treshold)\n",
        "    # filter features with high correlation (variance under treshold)\n",
        "    raked_matrix = np.delete(normalized_matrix, bool_mask, axis=1)\n",
        "    print(f'OUTPUT SHAPE: {raked_matrix.shape}')\n",
        "    return raked_matrix"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLHhdTn56Ywf",
        "outputId": "0456193b-7ca4-4253-cb0f-54f222bfb86f"
      },
      "source": [
        "ftt_reduced = reduce_matrix(ftt_matrix, variance_treshold=0.01)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT SHAPE: (8157, 1492)\n",
            "OUTPUT SHAPE: (8157, 239)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijZGf84GPuQC"
      },
      "source": [
        "### Save matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg2Li00Fgfdh"
      },
      "source": [
        "with open('/content/drive/MyDrive/nlp/ftt_serie_10000.npy', 'wb') as output_file:\n",
        "    np.save(output_file, ftt_reduced)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfyvHceT_WGg"
      },
      "source": [
        "### Load matrix from storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnXvvRlU_fpm"
      },
      "source": [
        "ftt_reduced = np.load('/content/drive/MyDrive/nlp/ftt_serie_10000.npy')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9svTIM7l1Mm"
      },
      "source": [
        "### Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu2EI9Ty6osz"
      },
      "source": [
        "def generate_clusters(\n",
        "    matrix: np.ndarray,\n",
        "    n_clusters: int\n",
        ") -> KMeans:\n",
        "    # generate word clusters using the KMeans algorithm.\n",
        "    print(\"\\nClustering started\")\n",
        "    # Instantiate KMeans clusterer for n_clusters\n",
        "    km_model = KMeans(n_clusters=n_clusters, random_state=3)\n",
        "    # create clusters\n",
        "    km_model.fit(matrix)\n",
        "    print(\"Clustering finished\")\n",
        "    return km_model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eym-gUz7AOSc"
      },
      "source": [
        "### Create clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPhX4J3Z69Hx",
        "outputId": "ad73d6d7-6f52-49a0-beb9-92201f8d8b75"
      },
      "source": [
        "ftt_clusters = generate_clusters(ftt_reduced, 50)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Clustering started\n",
            "Clustering finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVZTIGMtAjFP"
      },
      "source": [
        "### Cluster utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m5VxwFj7pvE"
      },
      "source": [
        "def display_summary(clusters: KMeans):\n",
        "    cluster_count = Counter(sorted(clusters.labels_))\n",
        "    for cluster in cluster_count:\n",
        "        print (\"Cluster#\", cluster,\" - Total words:\", cluster_count[cluster])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oN0JpYkuRdp"
      },
      "source": [
        "def annotate_dataframe(clusters: KMeans, df: pd.DataFrame, col_name: str):\n",
        "    cluster_count = Counter(sorted(clusters.labels_))\n",
        "    #sort cluster centers by proximity to centroid\n",
        "    order_centroids = clusters.cluster_centers_.argsort()[:, ::-1] \n",
        "\n",
        "    clusters_df = np.zeros(len(df))\n",
        "    \n",
        "    for cluster_idx in cluster_count:\n",
        "        # get words inside each cluster\n",
        "        cluster_words = np.where(clusters.labels_ == cluster_idx)[0]\n",
        "        # anotate all chats in cluster\n",
        "        for idx in cluster_words:\n",
        "            clusters_df[idx] = int(cluster_idx)\n",
        "\n",
        "    df[col_name] = clusters_df"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t5ERBEkApTt"
      },
      "source": [
        "### Show info about clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNljj0S2QNqE",
        "outputId": "4495e165-ea28-4394-815b-a7403ac6a469"
      },
      "source": [
        "display_summary(ftt_clusters)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster# 0  - Total words: 1620\n",
            "Cluster# 1  - Total words: 42\n",
            "Cluster# 2  - Total words: 293\n",
            "Cluster# 3  - Total words: 16\n",
            "Cluster# 4  - Total words: 61\n",
            "Cluster# 5  - Total words: 16\n",
            "Cluster# 6  - Total words: 32\n",
            "Cluster# 7  - Total words: 26\n",
            "Cluster# 8  - Total words: 565\n",
            "Cluster# 9  - Total words: 18\n",
            "Cluster# 10  - Total words: 20\n",
            "Cluster# 11  - Total words: 47\n",
            "Cluster# 12  - Total words: 34\n",
            "Cluster# 13  - Total words: 2018\n",
            "Cluster# 14  - Total words: 375\n",
            "Cluster# 15  - Total words: 11\n",
            "Cluster# 16  - Total words: 62\n",
            "Cluster# 17  - Total words: 38\n",
            "Cluster# 18  - Total words: 333\n",
            "Cluster# 19  - Total words: 19\n",
            "Cluster# 20  - Total words: 121\n",
            "Cluster# 21  - Total words: 17\n",
            "Cluster# 22  - Total words: 47\n",
            "Cluster# 23  - Total words: 164\n",
            "Cluster# 24  - Total words: 45\n",
            "Cluster# 25  - Total words: 8\n",
            "Cluster# 26  - Total words: 600\n",
            "Cluster# 27  - Total words: 58\n",
            "Cluster# 28  - Total words: 5\n",
            "Cluster# 29  - Total words: 34\n",
            "Cluster# 30  - Total words: 28\n",
            "Cluster# 31  - Total words: 27\n",
            "Cluster# 32  - Total words: 551\n",
            "Cluster# 33  - Total words: 181\n",
            "Cluster# 34  - Total words: 35\n",
            "Cluster# 35  - Total words: 3\n",
            "Cluster# 36  - Total words: 39\n",
            "Cluster# 37  - Total words: 11\n",
            "Cluster# 38  - Total words: 8\n",
            "Cluster# 39  - Total words: 38\n",
            "Cluster# 40  - Total words: 7\n",
            "Cluster# 41  - Total words: 88\n",
            "Cluster# 42  - Total words: 52\n",
            "Cluster# 43  - Total words: 136\n",
            "Cluster# 44  - Total words: 29\n",
            "Cluster# 45  - Total words: 2\n",
            "Cluster# 46  - Total words: 23\n",
            "Cluster# 47  - Total words: 9\n",
            "Cluster# 48  - Total words: 114\n",
            "Cluster# 49  - Total words: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz1ThhFoAuYQ"
      },
      "source": [
        "### Annotate cluster for each row in dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "628xHBsKvEXw"
      },
      "source": [
        "df_test = df_test.copy()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5adupRW8v7vk"
      },
      "source": [
        "annotate_dataframe(ftt_clusters, df_test, 'ftt_clusters')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFKi61q3cjhf"
      },
      "source": [
        "df_test.to_csv(f'/content/drive/MyDrive/nlp/ftt_clusters_df.csv', index=False)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWEWYqPvA5FE"
      },
      "source": [
        "### Explore results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7jOXlqFw_Lu"
      },
      "source": [
        "ftt_group = df_test.groupby('ftt_clusters')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfVW3ijhA88m"
      },
      "source": [
        "Get toxicity score for each cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIkBmlPAlCoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de76f7e-9e21-4bb9-96c2-e48056d88d09"
      },
      "source": [
        "ftt_group['toxicity'].sum() / ftt_group.size()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ftt_clusters\n",
              "0.0     0.114352\n",
              "1.0     0.214286\n",
              "2.0     0.109215\n",
              "3.0     0.062500\n",
              "4.0     0.213115\n",
              "5.0     0.125000\n",
              "6.0     0.125000\n",
              "7.0     0.000000\n",
              "8.0     0.097345\n",
              "9.0     0.055556\n",
              "10.0    0.050000\n",
              "11.0    0.106383\n",
              "12.0    0.117647\n",
              "13.0    0.107532\n",
              "14.0    0.109333\n",
              "15.0    0.363636\n",
              "16.0    0.112903\n",
              "17.0    0.131579\n",
              "18.0    0.093093\n",
              "19.0    0.157895\n",
              "20.0    0.132231\n",
              "21.0    0.176471\n",
              "22.0    0.106383\n",
              "23.0    0.170732\n",
              "24.0    0.066667\n",
              "25.0    0.000000\n",
              "26.0    0.095000\n",
              "27.0    0.017241\n",
              "28.0    0.000000\n",
              "29.0    0.058824\n",
              "30.0    0.142857\n",
              "31.0    0.037037\n",
              "32.0    0.094374\n",
              "33.0    0.110497\n",
              "34.0    0.228571\n",
              "35.0    0.333333\n",
              "36.0    0.051282\n",
              "37.0    0.000000\n",
              "38.0    0.000000\n",
              "39.0    0.236842\n",
              "40.0    0.000000\n",
              "41.0    0.102273\n",
              "42.0    0.076923\n",
              "43.0    0.139706\n",
              "44.0    0.103448\n",
              "45.0    0.000000\n",
              "46.0    0.043478\n",
              "47.0    0.111111\n",
              "48.0    0.175439\n",
              "49.0    0.096774\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLOYxeM1BaQk"
      },
      "source": [
        "### Explore clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtgbl_8idr6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a2bcb1-226b-43f1-9246-e843d96836d1"
      },
      "source": [
        "ftt_group.get_group(23)['text']"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "494                                           shutup nerd\n",
              "507                                            then i ded\n",
              "509                                             fair play\n",
              "524                                                 chill\n",
              "531                                               a trick\n",
              "536                                                    Oh\n",
              "542                               kewl you still are 2-10\n",
              "548                                                  I am\n",
              "549                                        Skeleton pussy\n",
              "555                          little fairplay rusians shit\n",
              "556             well if you remuse it will be uncount map\n",
              "587                                                  lmao\n",
              "598                            Cant even bark to make fun\n",
              "632                                          so nice game\n",
              "640                                                     (\n",
              "641                                                   wtf\n",
              "658                                                     s\n",
              "669                                team reported and afk \n",
              "670                                          plz end fast\n",
              "714                                                    ff\n",
              "773                       i gotta take some deep breathes\n",
              "779                                          Whats wrong?\n",
              "780                                                  Que?\n",
              "782                                              nice bkb\n",
              "787                                      from the offlane\n",
              "794                                                 gg wp\n",
              "808                                                 tard?\n",
              "811                                                   LOL\n",
              "824                                      imma piss on her\n",
              "840                                                   XDD\n",
              "845                                                   Gr8\n",
              "854                                               5 death\n",
              "859                                             shes fine\n",
              "873                                              16 kills\n",
              "874                                             dont talk\n",
              "876                                   16 kills still lose\n",
              "877                                    and u loosing game\n",
              "881                                            u cant win\n",
              "882                                     they really think\n",
              "885                                             underlord\n",
              "887                                                   2-9\n",
              "889                                            ur support\n",
              "890                                   so its ok if u feed\n",
              "892                                               we rosh\n",
              "926                                             fat nigga\n",
              "927                                            feels good\n",
              "946                               or do you want gay porn\n",
              "957                                            6 GANHAM N\n",
              "984                                      report alche plz\n",
              "988                                      report alche plz\n",
              "1003                                                  Lol\n",
              "1031                                           who mid XD\n",
              "1038                               scared of one fat guy?\n",
              "1044                                        u r so bad SF\n",
              "1048                                                  ???\n",
              "1050                                          why so bad?\n",
              "1062                                               PLSSSS\n",
              "1063                                          REPORTEN OD\n",
              "1067                                           gg no team\n",
              "1069                                                  PLS\n",
              "1071                                                  LOL\n",
              "1088                                                 AHHA\n",
              "1094                                For everyone but one.\n",
              "1121                                           close game\n",
              "1123        i never seen some1 lose mid that hard with sf\n",
              "1124                                                   wp\n",
              "1128                                               xDDDDD\n",
              "1130                  when we lost top tower sf was lvl 7\n",
              "1132                                               3 vs 7\n",
              "1133                                                  wtf\n",
              "1145                                                  why\n",
              "1146                                                 Gege\n",
              "1148                                                 gggg\n",
              "1150                                                sorry\n",
              "1154                                    playing with noob\n",
              "1155    0reaction team 0 def team 0 info team pls ff e...\n",
              "1158                                          finish fast\n",
              "1159                                                  plz\n",
              "1161                                                ss to\n",
              "1165                                i will burn you alive\n",
              "1166                                  finger you to death\n",
              "1167                 yes with my ultimate fingering skill\n",
              "1168        i did not see u finger me to death even once?\n",
              "1171                                               my god\n",
              "1173                                                 AND?\n",
              "1179                                why are you so pissed\n",
              "1183                              i'm really not, sry man\n",
              "1185                                  FUCK UR REFRACT LOL\n",
              "1186                                                  end\n",
              "1187                                             pro they\n",
              "1191                                     IM PASSIVBE EHHE\n",
              "1200                                               2 slow\n",
              "1201                                           nice cheat\n",
              "1206                                                  lol\n",
              "1207                                              5 x bf?\n",
              "1212                                                 meow\n",
              "1213          damn, now they know there are 4 of them bot\n",
              "1217                         what kind of vision is this \n",
              "1220                                  impossible game gg \n",
              "1229                                         you will see\n",
              "1231                                          i win game \n",
              "1232                                      whatya gonna do\n",
              "1233                                         you will see\n",
              "1234                                            salty? :)\n",
              "1244                                      dondo confirmed\n",
              "1245                                                xDDDD\n",
              "1252                                                  YEA\n",
              "1253                            inviz can win the game ;]\n",
              "1284                                               report\n",
              "1285                                                QUE,?\n",
              "1287                                                   ok\n",
              "1289                                           AND JUNGLE\n",
              "1290                                    we lost all lanes\n",
              "1291                                           and roshan\n",
              "1292                            kkkkkkkkkkkkkkkkkkkkkkkkk\n",
              "1293                                           comend plz\n",
              "1294                                               report\n",
              "1297                                                recon\n",
              "1298                                               coming\n",
              "1303                               why am solo on top..:9\n",
              "1304                                     rubick pro brain\n",
              "1311                                           not at all\n",
              "1331                 learn to not overextend in solo lane\n",
              "1344                                  you dumb and blind?\n",
              "1347                          but that's hardly his fault\n",
              "1362                       Get on your own servers retard\n",
              "1363           at least im doing better than LC ¯\\_(ツ)_/¯\n",
              "1368                                            report lc\n",
              "1369                                                  end\n",
              "1370                                      haha report lc?\n",
              "1372                                               We are\n",
              "1373                         ARCANA TO EVERYONE THAT DOES\n",
              "1374    remember when legion died 7 times bot and then...\n",
              "1379                                          but fuck LC\n",
              "1380                                       Lc gave you ez\n",
              "1382                                    gg sorry about lc\n",
              "1384                                             sad game\n",
              "1385                                           Yall didn'\n",
              "1386                                         report slark\n",
              "1389                                               report\n",
              "1396                                       juanitoooooooo\n",
              "1397                                              yaaaaaa\n",
              "1398                                        kos sher nago\n",
              "1406                                              wowkwok\n",
              "1409                                         nc try nigga\n",
              "1411                                                    G\n",
              "1412                                                  GGG\n",
              "1415                                                  gGG\n",
              "1420                                                  hey\n",
              "1445                                             hi pudge\n",
              "1459                                                  wtf\n",
              "1481                                                 Haha\n",
              "1482                                                 aray\n",
              "1483                                                 Haha\n",
              "1488                                                   SS\n",
              "1491                                               Hahaha\n",
              "1492                                                hahaa\n",
              "1498                  pls report sd. he is a russian scim\n",
              "1505                                        why even try?\n",
              "1506                                               Weaver\n",
              "1507                                                 ????\n",
              "1521                                                   ok\n",
              "1626                                         i shall wait\n",
              "1783                                                  rly\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rV-eoA2Z20S-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}